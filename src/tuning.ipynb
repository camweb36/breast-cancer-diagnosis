{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, ParameterGrid\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "file = open('../data/data_prep.save', 'rb')\n",
    "other_sets, test_sets = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_Pipeline(preprocessor, clf, rs_index, param_grid, xgbc=False, rs=True):\n",
    "    \n",
    "    random_state = 42 * rs_index\n",
    "\n",
    "    X_other, y_other = other_sets[rs_index]\n",
    "\n",
    "    kf = KFold(n_splits=5,shuffle=True,random_state=random_state)\n",
    "    \n",
    "    if xgbc:\n",
    "        clf.set_params(seed=random_state)\n",
    "    if rs:\n",
    "        clf.set_params(random_state=random_state)\n",
    "    \n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('classifier', clf)])\n",
    "\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, \n",
    "                            scoring='accuracy',\n",
    "                            cv=kf, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "    grid.fit(X_other, y_other)\n",
    "    \n",
    "    results = pd.DataFrame(grid.cv_results_)\n",
    "    print(results)\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def simpleLogisticPipeline(preprocessor, rs_index):\n",
    "    \n",
    "    X_train, y_train = other_sets[rs_index]\n",
    "    clf = LogisticRegression(penalty='none', max_iter=100000, random_state=rs_index*42)\n",
    "    \n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('classifier', clf)])\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_ftrs = list(other_sets[0][0].columns)\n",
    "preprocessor = ColumnTransformer(transformers=[('std', StandardScaler(), std_ftrs)])\n",
    "\n",
    "param_grid_L1L = {'classifier__C': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4],\n",
    "                  'classifier__max_iter': [100000]}\n",
    "param_grid_L2L = {'classifier__C': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4],\n",
    "                  'classifier__max_iter': [100000]}\n",
    "param_grid_ENL = {'classifier__C': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4],\n",
    "                  'classifier__l1_ratio': [0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99],\n",
    "                  'classifier__max_iter': [100000]}\n",
    "param_grid_RFC = {'classifier__max_features': [1, 3, 5, 10, 20, None],\n",
    "                  'classifier__max_depth': [1, 3, 5, 10, 20, None],\n",
    "                  'classifier__min_samples_split': [2, 5, 10]}\n",
    "param_grid_SVC = {'classifier__gamma': [1e-2, 1e-1, 1e0, 1e1, 1e2, 'auto', 'scale'],\n",
    "                  'classifier__C': np.logspace(-1, 1, 5)}\n",
    "param_grid_KNN = {'classifier__n_neighbors': [1, 2, 3, 5, 10, 30, 100, 200], \n",
    "                  'classifier__weights': ['uniform', 'distance']}\n",
    "param_grid_XGB = {'classifier__max_depth': [1, 3, 5, 10, 30, 100],\n",
    "                  'classifier__min_child_weight': [1, 3, 5, 7],\n",
    "                  'classifier__gamma': [0, 0.1, 0.2 , 0.3, 0.4],\n",
    "                  'classifier__subsample': [0.5, 0.66, 0.75, 1],\n",
    "                  'classifier__colsample_bytree': [0.3, 0.4, 0.5, 0.7, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "l1l = LogisticRegression(penalty='l1', solver='saga') # random_state\n",
    "l2l = LogisticRegression(penalty='l2', solver='saga') # random_state\n",
    "enl = LogisticRegression(penalty='elasticnet', solver='saga') # random_state\n",
    "rfc = RandomForestClassifier() # random_state\n",
    "svc = SVC() # random_state\n",
    "knn = KNeighborsClassifier()\n",
    "xgb = XGBClassifier() # seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [3:16:11<00:00, 1177.19s/it] \n"
     ]
    }
   ],
   "source": [
    "logistic_models = []\n",
    "l1_models = []\n",
    "l2_models = []\n",
    "en_models = []\n",
    "rf_models = []\n",
    "sv_models = []\n",
    "knn_models = []\n",
    "xgb_models = []\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    \n",
    "    model = simpleLogisticPipeline(preprocessor, i)\n",
    "    logistic_models.append(model)\n",
    "    \n",
    "    model = ML_Pipeline(preprocessor, l1l, i, param_grid_L1L, xgbc=False, rs=True)\n",
    "    l1_models.append(model)\n",
    "    \n",
    "    model = ML_Pipeline(preprocessor, l2l, i, param_grid_L2L, xgbc=False, rs=True)\n",
    "    l2_models.append(model)\n",
    "    \n",
    "    model = ML_Pipeline(preprocessor, enl, i, param_grid_ENL, xgbc=False, rs=True)\n",
    "    en_models.append(model)\n",
    "    \n",
    "    model = ML_Pipeline(preprocessor, rfc, i, param_grid_RFC, xgbc=False, rs=True)\n",
    "    rf_models.append(model)\n",
    "    \n",
    "    model = ML_Pipeline(preprocessor, svc, i, param_grid_SVC, xgbc=False, rs=True)\n",
    "    sv_models.append(model)\n",
    "    \n",
    "    model = ML_Pipeline(preprocessor, knn, i, param_grid_KNN, xgbc=False, rs=False)\n",
    "    knn_models.append(model)\n",
    "    \n",
    "    model = ML_Pipeline(preprocessor, xgb, i, param_grid_XGB, xgbc=True, rs=False)\n",
    "    xgb_models.append(model)\n",
    "    \n",
    "    \n",
    "file = open('../results/log_models_tuned.save', 'wb')\n",
    "pickle.dump(logistic_models, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../results/l1_models_tuned.save', 'wb')\n",
    "pickle.dump(l1_models, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../results/l2_models_tuned.save', 'wb')\n",
    "pickle.dump(l2_models, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../results/en_models_tuned.save', 'wb')\n",
    "pickle.dump(en_models, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../results/rf_models_tuned.save', 'wb')\n",
    "pickle.dump(rf_models, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../results/sv_models_tuned.save', 'wb')\n",
    "pickle.dump(sv_models, file)\n",
    "file.close()\n",
    "\n",
    "file = open('../results/knn_models_tuned.save', 'wb')\n",
    "pickle.dump(knn_models, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
